{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "87bc41f967274e87bd1842563ba1f5a6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# ID2214/FID3214 Assignment 4 Group no. [1]\n",
    "### Project members: \n",
    "[Patrik Zhong, pzhong@kth.se]\n",
    "[Edvin Walleborn, edvinw@kth.se]\n",
    "[Alexander Carlsson, alecarls@kth.se]\n",
    "\n",
    "\n",
    "### Declaration\n",
    "By submitting this solution, it is hereby declared that all individuals listed above have contributed to the solution, either with code that appear in the final solution below, or with code that has been evaluated and compared to the final solution, but for some reason has been excluded. It is also declared that all project members fully understand all parts of the final solution and can explain it upon request.\n",
    "\n",
    "It is furthermore declared that the code below is a contribution by the project members only, and specifically that no part of the solution has been copied from any other source (except for lecture slides at the course ID2214/FID3214) and no part of the solution has been provided by someone not listed as project member above.\n",
    "\n",
    "It is furthermore declared that it has been understood that no other library/package than the Python 3 standard library, NumPy, pandas, time and sklearn.tree, may be used in the solution for this assignment.\n",
    "\n",
    "### Required to run/Declaration of used libraries\n",
    "Uses rdkit. do the pip install\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6390281e5c234ac090cc6780edbc68f4",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Load NumPy, pandas, time and DecisionTreeClassifier from sklearn.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "a950f6c9b3644bf2a8c694214b0a01e9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1670505868351,
    "source_hash": "a2c44af8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import rdkit.Chem.rdMolDescriptors as d\n",
    "import rdkit.Chem.Lipinski as l\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "e56ab9c7b3cf453a80f0d2d53ccdd29f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 44,
    "execution_start": 1670504194027,
    "source_hash": "e2b424b8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================== COLUMN FILTER ===================================== #\n",
    "# =========================================== COLUMN FILTER ===================================== #\n",
    "\n",
    "globalTestList = [] # only used for print somewhere\n",
    "def create_column_filter(df):\n",
    "    dfnew = df.copy()    \n",
    "    column_filter = []\n",
    "    for col in dfnew.columns:\n",
    "        if col == 'CLASS' or col == 'ID':\n",
    "            column_filter.append(col)\n",
    "            continue\n",
    "        \n",
    "        if dfnew[col].isna().all():\n",
    "            dfnew.drop(labels=col, axis=1, inplace = True)\n",
    "        \n",
    "        elif(dfnew[col].dropna().nunique() <= 1):\n",
    "            dfnew.drop(col, axis = 1, inplace = True)\n",
    "        \n",
    "        else:\n",
    "            column_filter.append(col)\n",
    "          \n",
    "    return dfnew, column_filter\n",
    "\n",
    "def apply_column_filter(df, column_filter):\n",
    "    dfnew = df.copy()\n",
    "    dfnew= dfnew.filter(items = column_filter, axis = 1)\n",
    "\n",
    "    return dfnew\n",
    "\n",
    "# =========================================== NORMALIZATION ===================================== #\n",
    "# =========================================== NORMALIZATION ===================================== #\n",
    "\n",
    "def create_normalization(df, normalizationtype):\n",
    "    dfnew = df.copy()\n",
    "    #display(dfnew)\n",
    "    valueDict = {}\n",
    "\n",
    "\n",
    "    if normalizationtype == 'zscore':\n",
    "        for col in dfnew.columns:\n",
    "            \n",
    "            not_float = not pd.api.types.is_float_dtype(dfnew[col].dtypes)\n",
    "            not_int64 = not pd.api.types.is_int64_dtype(dfnew[col].dtypes)\n",
    "\n",
    "            if col == 'CLASS' or col == 'ID' or not_float and not_int64:\n",
    "                continue\n",
    "       \n",
    "            meanVal = dfnew[col].mean()\n",
    "            stdVal = dfnew[col].std()\n",
    "            dfnew[col] = dfnew[col].apply(lambda x: (x-meanVal)/stdVal)\n",
    "            valueDict[col] = (\"zscore\", meanVal, stdVal)\n",
    "\n",
    "    elif normalizationtype == 'minmax':\n",
    "        for col in dfnew.columns:\n",
    "                \n",
    "            not_float = not pd.api.types.is_float_dtype(dfnew[col].dtypes)\n",
    "            not_int64 = not pd.api.types.is_int64_dtype(dfnew[col].dtypes)\n",
    "\n",
    "            if col == 'CLASS' or col == 'ID' or not_float and not_int64:\n",
    "                continue\n",
    "           \n",
    "            minVal = dfnew[col].min()\n",
    "            maxVal = dfnew[col].max()\n",
    "            # for count, value in enumerate(dfnew[col]):\n",
    "            #     dfnew[col][count] = (value-minVal)/(maxVal-minVal) \n",
    "            dfnew[col] = dfnew[col].apply(lambda value: (value-minVal)/(maxVal-minVal)) \n",
    "            valueDict[col] = (\"minmax\", minVal, maxVal) \n",
    "                           \n",
    "\n",
    "    else: \n",
    "        print(\"Normalization type not recognized\")\n",
    "\n",
    "    return dfnew, valueDict\n",
    "\n",
    "def apply_normalization(df, normalization):\n",
    "    dfnew = df.copy()\n",
    "    for col in dfnew.columns:\n",
    "        not_float = not pd.api.types.is_float_dtype(dfnew[col].dtypes)\n",
    "        not_int64 = not pd.api.types.is_int64_dtype(dfnew[col].dtypes)\n",
    "\n",
    "        if col == 'CLASS' or col == 'ID' or not_float and not_int64:\n",
    "            continue\n",
    "\n",
    "        normalizationType = normalization[col][0] #minmax eller ztype       \n",
    "\n",
    "        if normalizationType == \"minmax\":          \n",
    "            minVal = normalization[col][1]\n",
    "            maxVal = normalization[col][2]\n",
    "            dfnew[col] = dfnew[col].apply(lambda value: (value-minVal)/(maxVal-minVal))\n",
    "            dfnew[col] = dfnew[col].apply(lambda x: 0.0 if x<0.0 else (1.0 if x > 1.0 else x))\n",
    "\n",
    "        if normalizationType == \"zscore\":\n",
    "            meanVal = normalization[col][1]\n",
    "            stdVal = maxVal = normalization[col][2]\n",
    "            dfnew[col] = df[col].apply(lambda x: (x-meanVal)/stdVal)\n",
    "\n",
    "    return dfnew\n",
    "\n",
    "# =========================================== IMPUTATION ===================================== #\n",
    "# =========================================== IMPUTATION ===================================== #\n",
    "\n",
    "def create_imputation(df):\n",
    "    dfnew = df.copy()\n",
    "    mappingDict = {}\n",
    "    #display(dfnew)\n",
    "    for col in dfnew.columns:\n",
    "        is_float = pd.api.types.is_float_dtype(dfnew[col].dtypes)\n",
    "        is_int64 = pd.api.types.is_int64_dtype(dfnew[col].dtypes)\n",
    "        is_object = pd.api.types.is_object_dtype(dfnew[col].dtypes)\n",
    "        is_category = pd.api.types.is_categorical_dtype(dfnew[col].dtypes)\n",
    "\n",
    "        #print(col)\n",
    "        #print(dfnew[col].dtypes)\n",
    "\n",
    "        if col == 'CLASS' or col == 'ID':\n",
    "            continue\n",
    "        elif (is_int64):\n",
    "            mean = dfnew[col].mean()\n",
    "            if pd.isna(mean):\n",
    "                mean = 0\n",
    "            dfnew[col].fillna(value=mean, inplace=True)\n",
    "            mappingDict[col] = (mean)\n",
    "        elif(is_float):\n",
    "            mean = dfnew[col].mean()\n",
    "            if pd.isna(mean):\n",
    "                mean = 0.0\n",
    "            dfnew[col].fillna(value=mean, inplace=True)\n",
    "            mappingDict[col] = (mean)\n",
    "        elif (is_object):\n",
    "            mode = dfnew[col].mode(dropna=True)[0]\n",
    "            if pd.isna(mode):\n",
    "                mode = \"\"\n",
    "            dfnew[col].fillna(value=mode, inplace=True)\n",
    "            mappingDict[col] = (mode)\n",
    "        elif(is_category):\n",
    "            mode = dfnew[col].mode(dropna=True)[0]\n",
    "            if pd.isna(mode):\n",
    "                mode = dfnew[col].categories[0]\n",
    "            dfnew[col].fillna(value=mode, inplace=True)\n",
    "            mappingDict[col] = (mode)\n",
    "        else:\n",
    "            print(\"no match on dtype in if-statement in (create_imputation)\")\n",
    "\n",
    "    #display(dfnew)\n",
    "    return dfnew, mappingDict\n",
    "\n",
    "\n",
    "def apply_imputation(df, imputation):\n",
    "        dfnew = df.copy()\n",
    "        for col in dfnew.columns:\n",
    "            if col == 'CLASS' or col == 'ID':\n",
    "                continue\n",
    "            else:\n",
    "                dfnew[col].fillna(value=imputation[col], inplace=True)\n",
    "        return dfnew\n",
    "\n",
    "# =========================================== DISCRETIZATION/BINNING ===================================== #\n",
    "# =========================================== DISCRETIZATION/BINNING ===================================== #\n",
    "\n",
    "def find_bin(x, binsVar):\n",
    "\n",
    "    for i, binn in enumerate(binsVar):\n",
    "        if x > binn and x <= binsVar[i+1]:\n",
    "            #print(i)\n",
    "            if not i in globalTestList:\n",
    "                globalTestList.append(i)\n",
    "            return i\n",
    "\n",
    "def create_bins(df, nobins, bintype):\n",
    "    dfnew = df.copy()\n",
    "    binning = {}\n",
    "    \n",
    "    #display(dfnew)\n",
    "\n",
    "    for col in dfnew.columns:\n",
    "\n",
    "        not_float = not pd.api.types.is_float_dtype(dfnew[col].dtypes)\n",
    "        not_int64 = not pd.api.types.is_int64_dtype(dfnew[col].dtypes)\n",
    "\n",
    "        if col == 'CLASS' or col == 'ID' or not_float and not_int64:\n",
    "            #Discretize is ignored\n",
    "            continue\n",
    "\n",
    "        res = None\n",
    "        binsVar = None\n",
    "        #Discretize columns from here on\n",
    "        if bintype == \"equal-width\":\n",
    "            res, binsVar = pd.cut(dfnew[col], bins=nobins, labels=False, retbins=True)\n",
    "        elif bintype == \"equal-size\":\n",
    "            #duplicates are set to drop due to error. discuss and lookup\n",
    "            res, binsVar = pd.qcut(dfnew[col], q=nobins, duplicates=\"drop\", labels=False, retbins=True)\n",
    "        else:\n",
    "            print(\"Not recognizable bintype to create_bins\")\n",
    "        \n",
    "        binsVar[0] = -np.inf\n",
    "        binsVar[-1] = np.inf\n",
    "        binning[col] = binsVar \n",
    "\n",
    "        dfnew[col] = dfnew[col].apply(lambda x: find_bin(x, binsVar))\n",
    "        dfnew[col] = dfnew[col].astype(\"category\")\n",
    "\n",
    "    return df, binning\n",
    "\n",
    "def apply_bins(df, binning):\n",
    "    #hint1\n",
    "    dfnew = df.copy()\n",
    "\n",
    "    for col in dfnew.columns:\n",
    "\n",
    "        not_float = not pd.api.types.is_float_dtype(dfnew[col].dtypes)\n",
    "        not_int64 = not pd.api.types.is_int64_dtype(dfnew[col].dtypes)\n",
    "\n",
    "        if col == 'CLASS' or col == 'ID' or not_float and not_int64:\n",
    "            #Discretize is ignored\n",
    "            continue\n",
    "\n",
    "        #hint2\n",
    "        res, binsVar = pd.cut(dfnew[col], bins=binning[col], labels=False, retbins=True)\n",
    "        \n",
    "        #apply bins to output instructions\n",
    "        dfnew[col] = dfnew[col].apply(lambda x: find_bin(x, binsVar))\n",
    "\n",
    "        #hint3\n",
    "        dfnew[col] = dfnew[col].astype(\"category\")\n",
    "\n",
    "        #hint4 already achieved. see print\n",
    "        #print(\"has0: {}\\nhas1: {}\\nhas2: {}\\nhas3: {}\\nhas4: {}\\nhas5: {}\\nhas6: {}\\nhas7: {}\\nhas8: {}\\nhas9: {}\\nmin: {}\\nmax: {}\".format(0 in res, 1 in res, 2 in res, 3 in res, 4 in res, 5 in res, 6 in res, 7 in res, 8 in res, 9 in res, res.min(), res.max()))\n",
    "\n",
    "    return dfnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "0776174e46ce4fa2b9496cc2ab1e7c3d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1670502254859,
    "source_hash": "fb1c708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.13\n",
      "NumPy version: 1.21.5\n",
      "Pandas version: 1.4.4\n",
      "sklearn version: 1.0.2\n",
      "rdkit version: 2022.09.1\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(f\"Python version: {python_version()}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"sklearn version: {sklearn.__version__}\")\n",
    "print(f\"rdkit version: {rdkit.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ce768eb26cbf4ca491f306c730d24b6d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## 1. First box of Assignent 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "11a816fb71de429c8b27a71c46ecb745",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2569,
    "execution_start": 1670504315482,
    "source_hash": "f603cce1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>fingerprint_col_1</th>\n",
       "      <th>fingerprint_col_2</th>\n",
       "      <th>fingerprint_col_3</th>\n",
       "      <th>fingerprint_col_4</th>\n",
       "      <th>fingerprint_col_5</th>\n",
       "      <th>fingerprint_col_6</th>\n",
       "      <th>fingerprint_col_7</th>\n",
       "      <th>fingerprint_col_8</th>\n",
       "      <th>fingerprint_col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>fingerprint_col_114</th>\n",
       "      <th>fingerprint_col_115</th>\n",
       "      <th>fingerprint_col_116</th>\n",
       "      <th>fingerprint_col_117</th>\n",
       "      <th>fingerprint_col_118</th>\n",
       "      <th>fingerprint_col_119</th>\n",
       "      <th>fingerprint_col_120</th>\n",
       "      <th>fingerprint_col_121</th>\n",
       "      <th>fingerprint_col_122</th>\n",
       "      <th>fingerprint_col_123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156253</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156254</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156255</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156256</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156257</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156258 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACTIVE  fingerprint_col_1  fingerprint_col_2  fingerprint_col_3  \\\n",
       "0            0                  0                  0                  1   \n",
       "1            0                  0                  1                  1   \n",
       "2            0                  1                  0                  1   \n",
       "3            0                  0                  0                  0   \n",
       "4            0                  1                  1                  0   \n",
       "...        ...                ...                ...                ...   \n",
       "156253       0                  0                  1                  0   \n",
       "156254       1                  0                  1                  0   \n",
       "156255       0                  0                  0                  1   \n",
       "156256       1                  0                  1                  0   \n",
       "156257       0                  1                  1                  0   \n",
       "\n",
       "        fingerprint_col_4  fingerprint_col_5  fingerprint_col_6  \\\n",
       "0                       0                  0                  0   \n",
       "1                       0                  1                  0   \n",
       "2                       1                  1                  1   \n",
       "3                       0                  1                  0   \n",
       "4                       0                  0                  0   \n",
       "...                   ...                ...                ...   \n",
       "156253                  0                  1                  0   \n",
       "156254                  1                  1                  0   \n",
       "156255                  0                  0                  0   \n",
       "156256                  0                  1                  1   \n",
       "156257                  0                  1                  0   \n",
       "\n",
       "        fingerprint_col_7  fingerprint_col_8  fingerprint_col_9  ...  \\\n",
       "0                       0                  1                  0  ...   \n",
       "1                       0                  0                  1  ...   \n",
       "2                       1                  0                  0  ...   \n",
       "3                       0                  0                  0  ...   \n",
       "4                       0                  0                  1  ...   \n",
       "...                   ...                ...                ...  ...   \n",
       "156253                  1                  1                  1  ...   \n",
       "156254                  0                  0                  1  ...   \n",
       "156255                  0                  0                  1  ...   \n",
       "156256                  0                  0                  0  ...   \n",
       "156257                  0                  0                  1  ...   \n",
       "\n",
       "        fingerprint_col_114  fingerprint_col_115  fingerprint_col_116  \\\n",
       "0                         0                    0                    0   \n",
       "1                         0                    0                    0   \n",
       "2                         1                    0                    0   \n",
       "3                         0                    0                    0   \n",
       "4                         0                    0                    0   \n",
       "...                     ...                  ...                  ...   \n",
       "156253                    1                    1                    1   \n",
       "156254                    0                    0                    0   \n",
       "156255                    0                    0                    1   \n",
       "156256                    1                    0                    0   \n",
       "156257                    0                    0                    1   \n",
       "\n",
       "        fingerprint_col_117  fingerprint_col_118  fingerprint_col_119  \\\n",
       "0                         0                    0                    0   \n",
       "1                         0                    0                    0   \n",
       "2                         0                    0                    0   \n",
       "3                         0                    0                    0   \n",
       "4                         0                    0                    0   \n",
       "...                     ...                  ...                  ...   \n",
       "156253                    0                    0                    0   \n",
       "156254                    0                    0                    1   \n",
       "156255                    0                    0                    0   \n",
       "156256                    0                    0                    0   \n",
       "156257                    0                    0                    0   \n",
       "\n",
       "        fingerprint_col_120  fingerprint_col_121  fingerprint_col_122  \\\n",
       "0                         1                    1                    1   \n",
       "1                         0                    1                    1   \n",
       "2                         0                    1                    1   \n",
       "3                         0                    1                    1   \n",
       "4                         0                    1                    1   \n",
       "...                     ...                  ...                  ...   \n",
       "156253                    1                    0                    1   \n",
       "156254                    0                    0                    1   \n",
       "156255                    0                    0                    1   \n",
       "156256                    0                    0                    1   \n",
       "156257                    1                    1                    1   \n",
       "\n",
       "        fingerprint_col_123  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         1  \n",
       "3                         0  \n",
       "4                         0  \n",
       "...                     ...  \n",
       "156253                    0  \n",
       "156254                    1  \n",
       "156255                    0  \n",
       "156256                    0  \n",
       "156257                    0  \n",
       "\n",
       "[156258 rows x 124 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load trainset fingerprints\n",
    "loaded_fprints = pd.read_csv(\"train_fprints.csv\")\n",
    "loaded_fprints.drop(columns=[\"Unnamed: 0\"], inplace = True)\n",
    "\n",
    "for col in loaded_fprints.columns:\n",
    "    loaded_fprints.rename(columns = {col : 'fingerprint_col_' + col}, inplace = True)\n",
    "loaded_fprints.rename(columns = {'fingerprint_col_0' : 'ACTIVE'}, inplace = True)\n",
    "\n",
    "# load testset fingerprints\n",
    "loaded_fprints_test = pd.read_csv(\"test_fprints.csv\")\n",
    "loaded_fprints_test.drop(columns=[\"Unnamed: 0\"], inplace = True)\n",
    "\n",
    "for col in loaded_fprints_test.columns:\n",
    "    loaded_fprints.rename(columns = {col : 'fingerprint_col_' + col}, inplace = True)\n",
    "\n",
    "display(loaded_fprints)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "61cb8edbcaad4aaa8bb84c686996ddc3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Valideringsset uppdelning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "81be73d2162b47ceb1c5df5d3b4daa77",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 18,
    "execution_start": 1670502254867,
    "source_hash": "d861b9e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# def dataprep(df):\n",
    "#     df1 = df.copy()\n",
    "#     df1.pop('SMILES')\n",
    "#     dframe = pd.DataFrame(SimpleImputer().fit_transform(df1), columns = df1.columns)\n",
    "\n",
    "#     normalized_df = (df1-df1.min())/(df1.max()-df1.min())\n",
    "#     # normalized_df = normalized_df.pop('SMILES')\n",
    "    \n",
    "#     return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "5163c1cf57544b5baec29b7d0e09b800",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1670505372181,
    "source_hash": "28cf5f17",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#kodruta\n",
    "def split(df):\n",
    "    training_df, test_df = train_test_split(df, test_size=0.2)\n",
    "    return training_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "995da9499569405581f01e9b68eee482",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# Create the files and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "f63bdbf3ec9d47ffb9c36fd6089adbb6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 573,
    "execution_start": 1670505630628,
    "source_hash": "97cb9faf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_w_features.csv\")\n",
    "test_df = pd.read_csv(\"test_w_features.csv\")\n",
    "train_df_new, validation_df = split(train_df)\n",
    "\n",
    "# prints for showing class balance in splits\n",
    "#print(\"train\")\n",
    "#print(train_df_new[\"ACTIVE\"].value_counts())\n",
    "#print(\"0/len\",train_df_new[\"ACTIVE\"].value_counts()[0]/len(train_df_new))\n",
    "#print(\"1/len\",train_df_new[\"ACTIVE\"].value_counts()[1]/len(train_df_new))\n",
    "\n",
    "#print(\"val\")\n",
    "#print(validation_df[\"ACTIVE\"].value_counts())\n",
    "#print(\"0/len\",validation_df[\"ACTIVE\"].value_counts()[0]/len(validation_df))\n",
    "#print(\"1/len\",validation_df[\"ACTIVE\"].value_counts()[1]/len(validation_df))\n",
    "\n",
    "\n",
    "\n",
    "fp_train, fp_validation = split(loaded_fprints)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3f3077b19934efda07cc780254e45ba",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### RF HYPERPARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9106302620884e97b73f08c777f33564",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5523,
    "execution_start": 1670506333955,
    "source_hash": "10a496df",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1cd5bc4b550 state=finished raised TerminatedWorkerError>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 359, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 794, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py\", line 177, in submit\n",
      "    return super(_ReusablePoolExecutor, self).submit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 1115, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
      "\n",
      "exception calling callback for <Future at 0x1cd5db8c430 state=finished raised TerminatedWorkerError>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 359, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 794, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py\", line 177, in submit\n",
      "    return super(_ReusablePoolExecutor, self).submit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 1115, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##MOLECULAR \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def hyperparametersRF(dftrain):\n",
    "    Y_train =  dftrain['ACTIVE']\n",
    "    X_train = dftrain.drop(columns = ['INDEX', 'SMILES', 'ACTIVE'])\n",
    "    # X_test = dftest.drop(columns = ['INDEX', 'SMILES'])\n",
    "    rfc = RandomForestClassifier(n_jobs=-1, max_features = 'sqrt', n_estimators=50, oob_score = 1)\n",
    "    param_grid = {'n_estimators': [200, 300, 1000, 1200], 'max_features': ['log2', 'sqrt']}\n",
    "\n",
    "    norm_train, dummy = create_normalization(X_train, normalizationtype=\"minmax\")\n",
    "\n",
    "    CV_rfc = GridSearchCV(estimator = rfc, param_grid = param_grid, scoring = 'roc_auc', cv = 5)\n",
    "    CV_rfc.fit(norm_train, Y_train)\n",
    "    print(CV_rfc.best_params_)\n",
    "\n",
    "# results given are:\n",
    "# {'max_features': 'auto', 'n_estimators': 1000}\n",
    "hyperparametersRF(train_df_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "089b3893f16c4ce8ba12b085fef728d2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4332,
    "execution_start": 1670506397387,
    "source_hash": "8426dc98",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##FINGERPRINTS \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def hyperparametersRF(dftrain):\n",
    "    Y_train =  dftrain['ACTIVE']\n",
    "    X_train = dftrain.drop(columns = ['ACTIVE'])\n",
    "\n",
    "    rfc = RandomForestClassifier(n_jobs=-1, max_features = 'sqrt', n_estimators=50, oob_score = 1)\n",
    "    param_grid = {'n_estimators': [200, 300, 1000, 1200], 'max_features': ['log2', 'sqrt']}\n",
    "\n",
    "    norm_train, dummy = create_normalization(X_train, normalizationtype=\"minmax\")\n",
    "\n",
    "    CV_rfc = GridSearchCV(estimator = rfc, param_grid = param_grid, scoring = 'roc_auc', cv = 5)\n",
    "    CV_rfc.fit(norm_train, Y_train)\n",
    "    print(CV_rfc.best_params_)\n",
    "    \n",
    "\n",
    "# results given are:\n",
    "# {'max_features': 'auto', 'n_estimators': 1000}\n",
    "hyperparametersRF(fp_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "74d34409412542498e7df922517ff5b7",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# KNN HYPERPARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a314504bbbaf4236adeab83df34fc3ae",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1206,
    "execution_start": 1670506222575,
    "source_hash": "32f8f4cf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MOLECULAR FEATURES\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def hyperparametersKNN(dftrain):\n",
    "    Y_train =  dftrain['ACTIVE']\n",
    "    X_train = dftrain.drop(columns = ['INDEX', 'SMILES', 'ACTIVE'])\n",
    "    # X_test = dftest.drop(columns = ['INDEX', 'SMILES'])\n",
    "    knc = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, \n",
    "        p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "    \n",
    "    norm_train, dummy = create_normalization(X_train, normalizationtype=\"minmax\")\n",
    "\n",
    "    param_grid = {'n_neighbors': [1, 2, 5, 10, 20, 40, 80, 160], 'weights': ['uniforms', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [10, 20, 30, 40, 50]}\n",
    "\n",
    "    CV_knc = GridSearchCV(estimator = knc, param_grid = param_grid, scoring = 'roc_auc', cv = 5)\n",
    "    CV_knc.fit(norm_train, Y_train)\n",
    "    print(CV_knc.best_params_)\n",
    "    return [1,2,3]\n",
    "\n",
    "# results given are:\n",
    "# {'max_features': 'auto', 'n_estimators': 1000}\n",
    "\n",
    "hyperparametersKNN(train_df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e28d3c3a114a46a38ab6c3e620a5bd89",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#FINGERPRINTS\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def hyperparametersKNN(dftrain):\n",
    "    Y_train =  dftrain['ACTIVE']\n",
    "    X_train = dftrain.drop(columns = ['ACTIVE']) \n",
    "    knc = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, \n",
    "        p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "    \n",
    "    norm_train, dummy = create_normalization(X_train, normalizationtype=\"minmax\")\n",
    "\n",
    "    param_grid = {'n_neighbors': [1, 2, 5, 10, 20, 40, 80, 160], 'weights': ['uniforms', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [10, 20, 30, 40, 50]}\n",
    "\n",
    "    CV_knc = GridSearchCV(estimator = knc, param_grid = param_grid, scoring = 'roc_auc', cv = 5)\n",
    "    CV_knc.fit(norm_train, Y_train)\n",
    "    print(CV_knc.best_params_)\n",
    "    return [1,2,3]\n",
    "\n",
    "# results given are:\n",
    "# {'max_features': 'auto', 'n_estimators': 1000}\n",
    "\n",
    "hyperparametersKNN(fp_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "739c0cd1c06e4beda4cbf1c3699354a3",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Algorithms and Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "dd549bd8b1184229a363c26fa1a89b55",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 22,
    "execution_start": 1670504917403,
    "source_hash": "f93867fc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##MOLEKYLER \n",
    "def randomforest(dftrain, dftest):\n",
    "    dftrain1 = dftrain.copy()\n",
    "    dftest1 = dftest.copy()\n",
    "    Y_train =  dftrain1['ACTIVE']\n",
    "    X_train = dftrain1.drop(columns = ['INDEX', 'SMILES', 'ACTIVE'])\n",
    "    Y_test = dftest1['ACTIVE']\n",
    "    X_test = dftest1.drop(columns = ['INDEX', 'SMILES', 'ACTIVE'])\n",
    "    \n",
    "\n",
    "    norm_train, dummy = create_normalization(X_train, normalizationtype=\"minmax\")\n",
    "    norm_test, dummy = create_normalization(X_test, normalizationtype=\"minmax\")\n",
    "\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=50, max_features=\"auto\", random_state=44)\n",
    "    rf_model.fit(norm_train, Y_train)\n",
    "\n",
    "    # predictions = rf_model.predict_proba(X_test)\n",
    "    \n",
    "    # predictionsdf = pd.DataFrame(predictions, columns=['0', '1'])\n",
    "    print(metrics.roc_auc_score(Y_test, rf_model.predict(norm_test)))\n",
    "    # print(predictionsdf)\n",
    "\n",
    "randomforest(train_df_new, validation_df)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1292d2487ba44bf88a68eae89f93cbb3",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##FINGERPRINTS\n",
    "def randomforest(dftrain, dftest):\n",
    "    dftrain1 = dftrain.copy()\n",
    "    dftest1 = dftest.copy()\n",
    "    Y_train =  dftrain1['ACTIVE']\n",
    "    X_train = dftrain1.drop(columns = ['ACTIVE'])\n",
    "    Y_test = dftest1['ACTIVE']\n",
    "    X_test = dftest1.drop(columns = ['ACTIVE'])\n",
    "    \n",
    "\n",
    "    imputed_X_train = pd.DataFrame(SimpleImputer().fit_transform(X_train), columns = X_train.columns)\n",
    "    normalized_X_train = (imputed_X_train-imputed_X_train.min())/(imputed_X_train.max()-imputed_X_train.min())\n",
    "    \n",
    "    imputed_X_test = pd.DataFrame(SimpleImputer().fit_transform(X_test), columns = X_test.columns)\n",
    "    normalized_X_test = (imputed_X_test-imputed_X_test.min())/(imputed_X_test.max()-imputed_X_test.min())\n",
    "\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=50, max_features=\"auto\", random_state=44)\n",
    "    rf_model.fit(normalized_X_train, Y_train)\n",
    "\n",
    "    # predictions = rf_model.predict_proba(X_test)\n",
    "    \n",
    "    # predictionsdf = pd.DataFrame(predictions, columns=['0', '1'])\n",
    "    print(metrics.roc_auc_score(Y_test, rf_model.predict(normalized_X_test)))\n",
    "    # print(predictionsdf)\n",
    "\n",
    "randomforest(train_df_new, validation_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e54eb3d708f94e578bb56eecb89e6498",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24252,
    "execution_start": 1670505057520,
    "source_hash": "145124ed",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##MOLEKYLER \n",
    "def randomforest(dftrain, dftest):\n",
    "    dftrain1 = dftrain.copy()\n",
    "    dftest1 = dftest.copy()\n",
    "    Y_train =  dftrain1['ACTIVE']\n",
    "    X_train = dftrain1.drop(columns = ['ACTIVE'])\n",
    "    Y_test = dftest1['ACTIVE']\n",
    "    X_test = dftest1.drop(columns = ['ACTIVE'])\n",
    "    \n",
    "\n",
    "    # imputed_X_train = pd.DataFrame(SimpleImputer().fit_transform(X_train), columns = X_train.columns)\n",
    "    # normalized_X_train = (imputed_X_train-imputed_X_train.min())/(imputed_X_train.max()-imputed_X_train.min())\n",
    "    \n",
    "    # imputed_X_test = pd.DataFrame(SimpleImputer().fit_transform(X_test), columns = X_test.columns)\n",
    "    # normalized_X_test = (imputed_X_test-imputed_X_test.min())/(imputed_X_test.max()-imputed_X_test.min())\n",
    "    \n",
    "    norm_train, dummy = create_normalization(X_train, normalizationtype=\"minmax\")\n",
    "    norm_test, dummy = create_normalization(X_test, normalizationtype=\"minmax\")\n",
    "\n",
    "\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=50, max_features=\"auto\", random_state=44)\n",
    "    rf_model.fit(norm_train, Y_train)\n",
    "\n",
    "    # predictions = rf_model.predict_proba(X_test)\n",
    "    \n",
    "    # predictionsdf = pd.DataFrame(predictions, columns=['0', '1'])\n",
    "    print(metrics.roc_auc_score(Y_test, rf_model.predict(norm_test)))\n",
    "    # print(predictionsdf)\n",
    "\n",
    "randomforest(fp_train, fp_validation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8c9ace2d619747dea8c2500be158f9f0",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hyperparameterBayes(dftrain):\n",
    "    Y_train =  dftrain['ACTIVE']\n",
    "    X_train = dftrain.drop(columns = ['INDEX', 'SMILES', 'ACTIVE'])\n",
    "    # X_test = dftest.drop(columns = ['INDEX', 'SMILES'])\n",
    "    clf = ComplementNB()\n",
    "    param_grid = {'n_estimators': [100, 200, 300, 1000], 'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "    CV_rfc = GridSearchCV(estimator = rfc, param_grid = param_grid, scoring = 'roc_auc', cv = 5)\n",
    "    CV_rfc.fit(X_train, Y_train)\n",
    "    print(CV_rfc.best_params_)\n",
    "    return [1,2,3]\n",
    "\n",
    "# results given are:\n",
    "# {'max_features': 'auto', 'n_estimators': 1000}\n",
    "hyperparametersRF(train_df_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "36dc9e63f86e41f88455c89a33410891",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 46975,
    "execution_start": 1670504984955,
    "source_hash": "474a7656",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "def cnb(dftrain, dftest):    \n",
    "    dftrain1 = dftrain.copy()\n",
    "    dftest1 = dftest.copy()\n",
    "    Y_train =  dftrain1['ACTIVE']\n",
    "    #X_train = dftrain1.drop(columns = ['INDEX', 'SMILES', 'ACTIVE'])\n",
    "    X_train = dftrain1.drop(columns = ['ACTIVE'])\n",
    "    Y_test = dftest1['ACTIVE']\n",
    "    #X_test = dftest1.drop(columns = ['INDEX', 'SMILES', 'ACTIVE'])\n",
    "    X_test = dftest1.drop(columns = ['ACTIVE'])\n",
    "\n",
    "    norm_train, dummy = create_normalization(X_train, normalizationtype=\"minmax\")\n",
    "    norm_test, dummy = create_normalization(X_test, normalizationtype=\"minmax\")\n",
    "\n",
    "    disc_train, dummy = create_bins(norm_train, nobins=10, bintype=\"equal-width\")\n",
    "    disc_validation, dummy = create_bins(norm_test, nobins=10, bintype=\"equal-width\")\n",
    "\n",
    "    clf = ComplementNB()\n",
    "    #clf.fit(normalized_X_train, Y_train)\n",
    "    clf.fit(disc_train, Y_train)\n",
    "    ComplementNB()\n",
    "    # predictions=clf.predict_proba(X_test)\n",
    "    # predictionsdf = pd.DataFrame(predictions, columns=['0', '1'])\n",
    "    # print(metrics.roc_auc_score(Y_test, clf.predict(normalized_X_test)))\n",
    "    print(metrics.roc_auc_score(Y_test, clf.predict(disc_validation)))\n",
    "\n",
    "#cnb(train_df_new, validation_df)\n",
    "cnb(fp_train, fp_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ab60ee19968b4476a4c64163d1b1f861",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9099,
    "execution_start": 1670503660955,
    "source_hash": "18aab565",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def knn(dftrain, dftest):\n",
    "    dftrain1 = dftrain.copy()\n",
    "    dftest1 = dftest.copy()\n",
    "    Y_train =  dftrain1['ACTIVE']\n",
    "    X_train = dftrain1.drop(columns = ['INDEX', 'SMILES', 'ACTIVE'])\n",
    "    Y_test = dftest1['ACTIVE']\n",
    "    X_test = dftest1.drop(columns = ['INDEX', 'SMILES', 'ACTIVE'])\n",
    "    \n",
    "\n",
    "    n_X_train, dummy = create_normalization(X_train, 'minmax')\n",
    "    n_X_test, dummy1 = create_normalization(X_test, 'minmax')\n",
    "    # imputed_X_train = pd.DataFrame(SimpleImputer().fit_transform(X_train), columns = X_train.columns)\n",
    "    # normalized_X_train = (imputed_X_train-imputed_X_train.min())/(imputed_X_train.max()-imputed_X_train.min())\n",
    "    \n",
    "    # imputed_X_test = pd.DataFrame(SimpleImputer().fit_transform(X_test), columns = X_test.columns)\n",
    "    # normalized_X_test = (imputed_X_test-imputed_X_test.min())/(imputed_X_test.max()-imputed_X_test.min())\n",
    "\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "    neigh.fit(n_X_train, Y_train)\n",
    "\n",
    "    # print(neigh.predict_proba(X_test))\n",
    "    print(metrics.roc_auc_score(Y_test, neigh.predict(n_X_test)))\n",
    "knn(train_df_new, validation_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4461a066790944478cd2ed14b4d1ea31",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "088f1dd5d0e449a590ccfb0abfa303a0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 49297,
    "execution_start": 1670504445369,
    "source_hash": "e5c5e92",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def knn(dftrain, dftest):\n",
    "    dftrain1 = dftrain.copy()\n",
    "    dftest1 = dftest.copy()\n",
    "    Y_train =  dftrain1['ACTIVE']\n",
    "    X_train = dftrain1.drop(columns = ['ACTIVE'])\n",
    "    Y_test = dftest1['ACTIVE']\n",
    "    X_test = dftest1.drop(columns = ['ACTIVE'])    \n",
    "\n",
    "    n_X_train, dummy = create_normalization(X_train, 'minmax')\n",
    "    n_X_test, dummy1 = create_normalization(X_test, 'minmax')\n",
    "    # imputed_X_train = pd.DataFrame(SimpleImputer().fit_transform(X_train), columns = X_train.columns)\n",
    "    # normalized_X_train = (imputed_X_train-imputed_X_train.min())/(imputed_X_train.max()-imputed_X_train.min())\n",
    "    \n",
    "    # imputed_X_test = pd.DataFrame(SimpleImputer().fit_transform(X_test), columns = X_test.columns)\n",
    "    # normalized_X_test = (imputed_X_test-imputed_X_test.min())/(imputed_X_test.max()-imputed_X_test.min())\n",
    "\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "    neigh.fit(n_X_train, Y_train)\n",
    "\n",
    "    # print(neigh.predict_proba(X_test))\n",
    "    print(metrics.roc_auc_score(Y_test, neigh.predict(n_X_test)))\n",
    "knn(fp_train, fp_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2a7cf0f4e0614c56ba49e2dbc7fd2037",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d5b21b1a-ec26-41e0-8ae3-fe1bc5b86ef4' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "ebbbc2eca3bc45f79e64b81b1e56b4bc",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
